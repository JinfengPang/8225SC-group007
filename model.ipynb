{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "1. data preparation\n",
    "2. model selection\n",
    "3. test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"./preprocessed/train.csv\" # TODO ===> Feature Engineering Result\n",
    "Y_LABEL_COL_NAME = \"monthly_rent\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y_df(data, y_column_name=Y_LABEL_COL_NAME):\n",
    "    feature_names = data.columns.to_list()\n",
    "    feature_names.remove(y_column_name)\n",
    "    X = data.loc[:, feature_names]\n",
    "    y = data.loc[:, [y_column_name]]\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for data_path in [f\"./preprocessed/train_{i}.csv\" for i in range(1, 4)]:\n",
    "    df_list.append(pd.read_csv(data_path))\n",
    "\n",
    "df = pd.DataFrame({\"index\": [i for i in range(0, 60000)]})\n",
    "for _df in df_list:\n",
    "    df = df.merge(_df, on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['index', 'flat_model_x']).rename(columns={\"flat_model_y\": \"flat_model\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(TRAIN_DATA_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_df = pd.read_csv(TRAIN_DATA_PATH)\n",
    "\n",
    "X_df, y_df = get_X_y_df(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rent_approval_date</th>\n",
       "      <th>town</th>\n",
       "      <th>block</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>lease_commence_date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>subzone</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2595.146199</td>\n",
       "      <td>257</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>67.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1.344518</td>\n",
       "      <td>103.738630</td>\n",
       "      <td>149</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>2438.227223</td>\n",
       "      <td>119</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>92.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1.330186</td>\n",
       "      <td>103.938717</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>2516.680515</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>67.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.332242</td>\n",
       "      <td>103.845643</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>2686.857477</td>\n",
       "      <td>250</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>149.0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.370239</td>\n",
       "      <td>103.962894</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>2665.537634</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.320502</td>\n",
       "      <td>103.863341</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>8</td>\n",
       "      <td>2416.700057</td>\n",
       "      <td>441</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>67.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1.366050</td>\n",
       "      <td>103.854168</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>27</td>\n",
       "      <td>2904.113924</td>\n",
       "      <td>95</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>83.0</td>\n",
       "      <td>53</td>\n",
       "      <td>1.286493</td>\n",
       "      <td>103.821434</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>17</td>\n",
       "      <td>2638.489123</td>\n",
       "      <td>862</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>122.0</td>\n",
       "      <td>22</td>\n",
       "      <td>1.355064</td>\n",
       "      <td>103.936507</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>24</td>\n",
       "      <td>2438.227223</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>123.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.318974</td>\n",
       "      <td>103.944076</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>25</td>\n",
       "      <td>2416.700057</td>\n",
       "      <td>445</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>67.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1.366980</td>\n",
       "      <td>103.855718</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rent_approval_date         town  block  flat_type  flat_model  \\\n",
       "0                       8  2595.146199    257          3          10   \n",
       "1                      16  2438.227223    119          4          10   \n",
       "2                      21  2516.680515    157          3           5   \n",
       "3                       7  2686.857477    250          6           3   \n",
       "4                      22  2665.537634     34          3           5   \n",
       "...                   ...          ...    ...        ...         ...   \n",
       "59995                   8  2416.700057    441          3          10   \n",
       "59996                  27  2904.113924     95          4           7   \n",
       "59997                  17  2638.489123    862          5           5   \n",
       "59998                  24  2438.227223     67          5          15   \n",
       "59999                  25  2416.700057    445          3          10   \n",
       "\n",
       "       floor_area_sqm  lease_commence_date  latitude   longitude  subzone  \\\n",
       "0                67.0                   17  1.344518  103.738630      149   \n",
       "1                92.0                   12  1.330186  103.938717        8   \n",
       "2                67.0                    5  1.332242  103.845643      128   \n",
       "3               149.0                   27  1.370239  103.962894       91   \n",
       "4                68.0                    6  1.320502  103.863341       12   \n",
       "...               ...                  ...       ...         ...      ...   \n",
       "59995            67.0                   13  1.366050  103.854168       31   \n",
       "59996            83.0                   53  1.286493  103.821434       52   \n",
       "59997           122.0                   22  1.355064  103.936507      118   \n",
       "59998           123.0                   11  1.318974  103.944076       10   \n",
       "59999            67.0                   13  1.366980  103.855718       31   \n",
       "\n",
       "       region  \n",
       "0           4  \n",
       "1           1  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  \n",
       "...       ...  \n",
       "59995       3  \n",
       "59996       0  \n",
       "59997       1  \n",
       "59998       1  \n",
       "59999       3  \n",
       "\n",
       "[60000 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer、Model Selection、Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, X=X_df.values, y=y_df.values, k_folds=5):\n",
    "        \"\"\"\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
    "        \"\"\"\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        self.k_fold = k_folds\n",
    "        self.model = model\n",
    "        self.trained = None\n",
    "\n",
    "    def cross_validate(self, metric=\"rmse\", k_fold=None):\n",
    "        \"\"\"Root Mean Square Error of Cross Validation\"\"\"\n",
    "        if metric == \"rmse\":\n",
    "            kf = KFold(self.k_fold if k_fold is None else k_fold, \n",
    "                       random_state=42, \n",
    "                       shuffle=True).get_n_splits(self.X_train)\n",
    "            # TODO other metrics?\n",
    "            rmse = np.sqrt(-cross_val_score(self.model, self.X_train, self.y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "            return (rmse)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def train(self):\n",
    "        self.trained = self.model.fit(self.X_train, self.y_train)\n",
    "        return self.trained\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        if self.trained is None:\n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "        return self.model.predict(X_test)\n",
    "    \n",
    "    def rmse_on_train(self):\n",
    "        y_pred = self.predict(self.X_train)\n",
    "        return np.sqrt(mean_squared_error(y_pred, self.y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection(trainer: Trainer, trainer_name=\"\", k_fold=None, metric=\"rmse\"):\n",
    "    cv = trainer.cross_validate(k_fold, metric=metric)\n",
    "    mean_cv = cv.mean()\n",
    "    std_cv = cv.std()\n",
    "    print(f\"trainer: {trainer_name} with {metric} | mean: {round(mean_cv, 5)}, std: {round(std_cv, 5)}\")\n",
    "\n",
    "# TODO: parameter grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "gboost_model = GradientBoostingRegressor(n_estimators=6000,\n",
    "                                learning_rate=0.01,\n",
    "                                max_depth=4,\n",
    "                                max_features='sqrt',\n",
    "                                min_samples_leaf=15,\n",
    "                                min_samples_split=10,\n",
    "                                loss='huber',\n",
    "                                random_state=42)\n",
    "gboost = Trainer(gboost_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jadeeeey/opt/anaconda3/envs/nus/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Jadeeeey/Desktop/GraduateCourses/CS5228/Project/repo/8225SC-group007/model.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Jadeeeey/Desktop/GraduateCourses/CS5228/Project/repo/8225SC-group007/model.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m gboost\u001b[39m.\u001b[39mcross_validate()\n",
      "\u001b[1;32m/Users/Jadeeeey/Desktop/GraduateCourses/CS5228/Project/repo/8225SC-group007/model.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Jadeeeey/Desktop/GraduateCourses/CS5228/Project/repo/8225SC-group007/model.ipynb#X45sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     kf \u001b[39m=\u001b[39m KFold(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_fold \u001b[39mif\u001b[39;00m k_fold \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m k_fold, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Jadeeeey/Desktop/GraduateCourses/CS5228/Project/repo/8225SC-group007/model.ipynb#X45sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Jadeeeey/Desktop/GraduateCourses/CS5228/Project/repo/8225SC-group007/model.ipynb#X45sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mget_n_splits(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Jadeeeey/Desktop/GraduateCourses/CS5228/Project/repo/8225SC-group007/model.ipynb#X45sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m# TODO other metrics?\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Jadeeeey/Desktop/GraduateCourses/CS5228/Project/repo/8225SC-group007/model.ipynb#X45sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     rmse \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(\u001b[39m-\u001b[39mcross_val_score(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_train, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_train, scoring\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mneg_mean_squared_error\u001b[39m\u001b[39m\"\u001b[39m, cv \u001b[39m=\u001b[39m kf))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Jadeeeey/Desktop/GraduateCourses/CS5228/Project/repo/8225SC-group007/model.ipynb#X45sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m (rmse)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Jadeeeey/Desktop/GraduateCourses/CS5228/Project/repo/8225SC-group007/model.ipynb#X45sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nus/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    560\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 562\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    563\u001b[0m     estimator\u001b[39m=\u001b[39mestimator,\n\u001b[1;32m    564\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[1;32m    565\u001b[0m     y\u001b[39m=\u001b[39my,\n\u001b[1;32m    566\u001b[0m     groups\u001b[39m=\u001b[39mgroups,\n\u001b[1;32m    567\u001b[0m     scoring\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m\"\u001b[39m: scorer},\n\u001b[1;32m    568\u001b[0m     cv\u001b[39m=\u001b[39mcv,\n\u001b[1;32m    569\u001b[0m     n_jobs\u001b[39m=\u001b[39mn_jobs,\n\u001b[1;32m    570\u001b[0m     verbose\u001b[39m=\u001b[39mverbose,\n\u001b[1;32m    571\u001b[0m     fit_params\u001b[39m=\u001b[39mfit_params,\n\u001b[1;32m    572\u001b[0m     pre_dispatch\u001b[39m=\u001b[39mpre_dispatch,\n\u001b[1;32m    573\u001b[0m     error_score\u001b[39m=\u001b[39merror_score,\n\u001b[1;32m    574\u001b[0m )\n\u001b[1;32m    575\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nus/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nus/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 309\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    311\u001b[0m         clone(estimator),\n\u001b[1;32m    312\u001b[0m         X,\n\u001b[1;32m    313\u001b[0m         y,\n\u001b[1;32m    314\u001b[0m         scorers,\n\u001b[1;32m    315\u001b[0m         train,\n\u001b[1;32m    316\u001b[0m         test,\n\u001b[1;32m    317\u001b[0m         verbose,\n\u001b[1;32m    318\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    319\u001b[0m         fit_params,\n\u001b[1;32m    320\u001b[0m         return_train_score\u001b[39m=\u001b[39mreturn_train_score,\n\u001b[1;32m    321\u001b[0m         return_times\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    322\u001b[0m         return_estimator\u001b[39m=\u001b[39mreturn_estimator,\n\u001b[1;32m    323\u001b[0m         error_score\u001b[39m=\u001b[39merror_score,\n\u001b[1;32m    324\u001b[0m     )\n\u001b[1;32m    325\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m indices\n\u001b[1;32m    326\u001b[0m )\n\u001b[1;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    330\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nus/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nus/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nus/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nus/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nus/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    727\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    728\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 729\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    731\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nus/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nus/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:532\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resize_state()\n\u001b[1;32m    531\u001b[0m \u001b[39m# fit the boosting stages\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m n_stages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_stages(\n\u001b[1;32m    533\u001b[0m     X_train,\n\u001b[1;32m    534\u001b[0m     y_train,\n\u001b[1;32m    535\u001b[0m     raw_predictions,\n\u001b[1;32m    536\u001b[0m     sample_weight_train,\n\u001b[1;32m    537\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rng,\n\u001b[1;32m    538\u001b[0m     X_val,\n\u001b[1;32m    539\u001b[0m     y_val,\n\u001b[1;32m    540\u001b[0m     sample_weight_val,\n\u001b[1;32m    541\u001b[0m     begin_at_stage,\n\u001b[1;32m    542\u001b[0m     monitor,\n\u001b[1;32m    543\u001b[0m )\n\u001b[1;32m    545\u001b[0m \u001b[39m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39mif\u001b[39;00m n_stages \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nus/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:610\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    603\u001b[0m         initial_loss \u001b[39m=\u001b[39m loss_(\n\u001b[1;32m    604\u001b[0m             y[\u001b[39m~\u001b[39msample_mask],\n\u001b[1;32m    605\u001b[0m             raw_predictions[\u001b[39m~\u001b[39msample_mask],\n\u001b[1;32m    606\u001b[0m             sample_weight[\u001b[39m~\u001b[39msample_mask],\n\u001b[1;32m    607\u001b[0m         )\n\u001b[1;32m    609\u001b[0m \u001b[39m# fit next stage of trees\u001b[39;00m\n\u001b[0;32m--> 610\u001b[0m raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_stage(\n\u001b[1;32m    611\u001b[0m     i,\n\u001b[1;32m    612\u001b[0m     X,\n\u001b[1;32m    613\u001b[0m     y,\n\u001b[1;32m    614\u001b[0m     raw_predictions,\n\u001b[1;32m    615\u001b[0m     sample_weight,\n\u001b[1;32m    616\u001b[0m     sample_mask,\n\u001b[1;32m    617\u001b[0m     random_state,\n\u001b[1;32m    618\u001b[0m     X_csc,\n\u001b[1;32m    619\u001b[0m     X_csr,\n\u001b[1;32m    620\u001b[0m )\n\u001b[1;32m    622\u001b[0m \u001b[39m# track loss\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[39mif\u001b[39;00m do_oob:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nus/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:245\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    242\u001b[0m     sample_weight \u001b[39m=\u001b[39m sample_weight \u001b[39m*\u001b[39m sample_mask\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m    244\u001b[0m X \u001b[39m=\u001b[39m X_csr \u001b[39mif\u001b[39;00m X_csr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m X\n\u001b[0;32m--> 245\u001b[0m tree\u001b[39m.\u001b[39mfit(X, residual, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    247\u001b[0m \u001b[39m# update tree leaves\u001b[39;00m\n\u001b[1;32m    248\u001b[0m loss\u001b[39m.\u001b[39mupdate_terminal_regions(\n\u001b[1;32m    249\u001b[0m     tree\u001b[39m.\u001b[39mtree_,\n\u001b[1;32m    250\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    257\u001b[0m     k\u001b[39m=\u001b[39mk,\n\u001b[1;32m    258\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nus/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nus/lib/python3.11/site-packages/sklearn/tree/_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1292\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \n\u001b[1;32m   1294\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1318\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1320\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_fit(\n\u001b[1;32m   1321\u001b[0m         X,\n\u001b[1;32m   1322\u001b[0m         y,\n\u001b[1;32m   1323\u001b[0m         sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[1;32m   1324\u001b[0m         check_input\u001b[39m=\u001b[39mcheck_input,\n\u001b[1;32m   1325\u001b[0m     )\n\u001b[1;32m   1326\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nus/lib/python3.11/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m builder\u001b[39m.\u001b[39mbuild(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gboost.cross_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgboost_model = XGBRegressor(learning_rate=0.01,\n",
    "                       n_estimators=6000,\n",
    "                       max_depth=4,\n",
    "                       min_child_weight=0,\n",
    "                       gamma=0.6,\n",
    "                       subsample=0.7,\n",
    "                       colsample_bytree=0.7,\n",
    "                       objective='reg:linear',\n",
    "                       nthread=-1,\n",
    "                       scale_pos_weight=1,\n",
    "                       seed=27,\n",
    "                       reg_alpha=0.00006,\n",
    "                       random_state=42)\n",
    "xgboost = Trainer(xgboost_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jadeeeey/opt/anaconda3/envs/nus/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [09:59:04] WARNING: /Users/runner/work/xgboost/xgboost/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/Jadeeeey/opt/anaconda3/envs/nus/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [09:59:09] WARNING: /Users/runner/work/xgboost/xgboost/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/Jadeeeey/opt/anaconda3/envs/nus/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [09:59:14] WARNING: /Users/runner/work/xgboost/xgboost/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/Jadeeeey/opt/anaconda3/envs/nus/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [09:59:20] WARNING: /Users/runner/work/xgboost/xgboost/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/Jadeeeey/opt/anaconda3/envs/nus/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [09:59:25] WARNING: /Users/runner/work/xgboost/xgboost/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([485.30099108, 479.90683504, 492.47248925, 479.1823819 ,\n",
       "       484.1739538 ])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost.cross_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jadeeeey/opt/anaconda3/envs/nus/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [10:02:42] WARNING: /Users/runner/work/xgboost/xgboost/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "460.3878115296174"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost.rmse_on_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=1200,\n",
    "                          max_depth=15,\n",
    "                          min_samples_split=5,\n",
    "                          min_samples_leaf=5,\n",
    "                          max_features=None,\n",
    "                          oob_score=True,\n",
    "                          random_state=42)\n",
    "rf = Trainer(rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jadeeeey/opt/anaconda3/envs/nus/lib/python3.11/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "412.95734832291424"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.rmse_on_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso\n",
    "lasso_model = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "lasso = Trainer(lasso_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "519.8426195922993"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.rmse_on_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Regressor\n",
    "svr_model = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003))\n",
    "svr = Trainer(svr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
