{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "1. data preparation\n",
    "2. model selection\n",
    "3. test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"./Dataset/train.csv\" # TODO ===> Feature Engineering Result\n",
    "Y_LABEL_COL_NAME = \"monthly_rent\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y_df(data, y_column_name=Y_LABEL_COL_NAME):\n",
    "    feature_names = data.columns.to_list()\n",
    "    feature_names.remove(y_column_name)\n",
    "    X = data.loc[:, feature_names]\n",
    "    y = data.loc[:, [y_column_name]]\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_df = pd.read_csv(TRAIN_DATA_PATH)\n",
    "\n",
    "X_df, y_df = get_X_y_df(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer、Model Selection、Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, X=X_df.values, y=y_df.values, k_folds=5):\n",
    "        \"\"\"\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
    "        \"\"\"\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        self.k_fold = k_folds\n",
    "        self.model = model\n",
    "        self.trained = None\n",
    "\n",
    "    def cross_validate(self, metric=\"rmse\", k_fold=None):\n",
    "        \"\"\"Root Mean Square Error of Cross Validation\"\"\"\n",
    "        if metric == \"rmse\":\n",
    "            kf = KFold(self.k_fold if k_fold is None else k_fold, \n",
    "                       random_state=42, \n",
    "                       shuffle=True).get_n_splits(self.X_train)\n",
    "            # TODO other metrics?\n",
    "            rmse = np.sqrt(-cross_val_score(self.model, self.X_train, self.y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "            return (rmse)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def train(self):\n",
    "        self.trained = self.model.fit(self.X_train, self.y_train)\n",
    "        return self.trained\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return self.trained.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection(trainer: Trainer, trainer_name=\"\", k_fold=None, metric=\"rmse\"):\n",
    "    cv = trainer.cross_validate(k_fold, metric=metric)\n",
    "    mean_cv = cv.mean()\n",
    "    std_cv = cv.std()\n",
    "    print(f\"trainer: {trainer_name} with {metric} | mean: {round(mean_cv, 5)}, std: {round(std_cv, 5)}\")\n",
    "\n",
    "# TODO: parameter grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "gboost_model = GradientBoostingRegressor(n_estimators=6000,\n",
    "                                learning_rate=0.01,\n",
    "                                max_depth=4,\n",
    "                                max_features='sqrt',\n",
    "                                min_samples_leaf=15,\n",
    "                                min_samples_split=10,\n",
    "                                loss='huber',\n",
    "                                random_state=42)\n",
    "gboost = Trainer(gboost_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgboost_model = XGBRegressor(learning_rate=0.01,\n",
    "                       n_estimators=6000,\n",
    "                       max_depth=4,\n",
    "                       min_child_weight=0,\n",
    "                       gamma=0.6,\n",
    "                       subsample=0.7,\n",
    "                       colsample_bytree=0.7,\n",
    "                       objective='reg:linear',\n",
    "                       nthread=-1,\n",
    "                       scale_pos_weight=1,\n",
    "                       seed=27,\n",
    "                       reg_alpha=0.00006,\n",
    "                       random_state=42)\n",
    "xgboost = Trainer(xgboost_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=1200,\n",
    "                          max_depth=15,\n",
    "                          min_samples_split=5,\n",
    "                          min_samples_leaf=5,\n",
    "                          max_features=None,\n",
    "                          oob_score=True,\n",
    "                          random_state=42)\n",
    "rf = Trainer(rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel Ridge\n",
    "krr_model = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "krr = Trainer(krr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso\n",
    "lasso_model = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "lasso = Trainer(lasso_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Regressor\n",
    "svr_model = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003))\n",
    "svr = Trainer(svr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
